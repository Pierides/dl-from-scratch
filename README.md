# 《深度学习入门：基于PyTorch和TensorFlow的理论与实战》

**作者：红色石头**

**出版社：清华大学出版社**

19世纪70 年代，电力的发明和应用掀起了第二次工业化高潮，从此改变了人们的生活方式，大大提高了人类的科技水平。现如今，深度学习（Deep Learning）技术也正在发挥同样的作用。纵观这近几年，深度学习发展非常迅速，发展势头一直高歌猛进。毫无疑问，深度学习技术正在影响着我们的日常生活和行为方式。


## 深度学习怎么学

深度学习怎么学？事实上，很多初学者常常会误入两大误区：一是找不到一本真正适合自己的教材或书本来学习，陷入到海量资源中手足无措；二是受制于数学理论知识，自认为数学基础不好而影响学习的主观性和积极性。

这两大误区很容易让初学者陷入到一种迷茫的状态。所以，第一步就是要放弃海量资源，选择一份真正适合自己的资料，好好研读下去！第二步就是重视实践。深度学习涉及的理论知识很多，有些人可能基础不是特别扎实，就想着从最底层的知识开始学起，概率论、线性代数、凸优化理论等。但是这样做比较耗时间，而且容易打消学习的积极性。啃书本和推导公式相对来说是比较枯燥的，远不如自己搭建一个简单的神经网络模型更能激发学习积极性。当然，基础理论知识非常重要！只是说，在入门的时候，最好先从顶层框架上有个系统的认识，然后再从实践到理论，有的放矢的查缺补漏深度学习知识点。从宏观到微观，从整体到细节，更有利于快速入门！ 

## 为什么写这本书

在学习深度学习的几年时间里，我学过一些国内外优秀的深度学习公开课程，口碑都很好；我也看过不少大牛老师写的高质量书籍，收获颇丰；我也在学习的过程中走过一些弯路，遇到一些坑，这些也是宝贵的经验。

我个人觉得，任何前沿技术，如深度学习，扎实的基础知识非常重要。而最好的基础知识的获取方式还是教材和书本。但是，反观现在一些深度学习方面的书籍，或多或少存在一些问题：

1、数学理论太多，公式多，起点高，对初学者不友善，容易削弱入门学习的积极性。

2、只讲深度学习框架，教你如何调包、调用库函数，不讲深度学习理论知识。容易造成一知半解，沦为“调包侠”。

3、理论与实战的脱节，过于侧重理论或者过于侧重实战，二者之间没有很好的融合。

基于以上这些问题，我认为写一本真正适合深度学习初学者的入门书籍非常必要。这样的书籍不仅要兼顾理论和实战，还应该将重难点知识通俗化讲解、全面细致。难度有阶梯性，照顾不同水平的读者。这样的书籍才能最大程度地让读者受益。

基于这样的考量，《深度学习入门：基于PyTorch与TensorFlow的理论与实战》跟大家见面了。

## 本书特色

我刚刚也说了，对于初学者而言，一本好的深度学习书籍，宗旨就是让读者能够轻轻松松地掌握知识、触类旁通。本书作为一本深度学习的入门书籍，对初学者是非常友好的。本书的内容来自于我多年的知识积累和技术沉淀，也是我的一份深度学习经验总结。

首先，这本书包含了Python的基本介绍。Python作为人工智能的首选语言，其重要性不言而喻。Python入门非常简单，本书将会对深度学习中所需的基本Python语法知识进行简明扼要的提炼和概括。如果有的读者之前没有接触过Python，那么本书将轻松带你入门。

其次，这本书介绍了如今主流的深度学习框架PyTorch和TensorFlow。通过本书，读者可以对这两个框架的基本语法和基础知识有一个系统的学习，夯实基础。如果你之前对PyTorch和TensorFlow不了解也没有关系，这本书也可以是这两个框架的知识学习手册。

然而，最重要的，这是一本关于深度学习的入门教程。我在编写该书的时候，从小白的视角出发，结合我多年的知识和经验，尽量将深度学习、神经网络的理论知识用通俗易懂的语言描绘出来。这本书能让读者真正了解、熟悉神经网络的结构和优化方法，也能帮助读者梳理一些容易被忽视的技术细节。例如最简单的梯度下降算法，它的公式来源和理论支持是什么？本书都会有详细的解释。

值得注意的是，我一贯的坚持是将复杂的理论简单化，这本书会将理论以平易化的语言描述清楚，但不会深陷于数学公式之中。这本书面向的深度学习的入门者和初学者，不会涉及太多太复杂的理论知识。因为入门深度学习，前期整体上的感性认识尤为重要。轻松入门，往往是比较正确的学习路线。我在编写该书的时候，也一直在把握这个分寸和尺度。如果想要学习更深层次、更高级的深度学习知识，读者可以查阅更多的书籍、会议论文、前沿技术等。
除此之外，深度学习更重要的是代码实践，这也是本书一直秉承的一个重点。这本书的另一个优势就是不仅讲理论知识，也配备了完整的实战项目和代码。从简单的逻辑回归，到浅层神经网络、深层神经网络，再到CNN、RNN，都会通过一个实际项目从零搭建神经网络，或者使用PyTorch、TensorFlow来构建更复杂的例如CNN、RNN模型解决问题。

本书的所有代码，我都开源放在了GitHub上，地址如下：

[https://github.com/RedstoneWill/dl-from-scratch](https://github.com/RedstoneWill/dl-from-scratch)

## 面向的读者

这是一本深度学习的入门书籍，也是一本关于Python、PyTorch、TensorFlow的工具手册；这是一本深度学习的理论书籍，也是一本教你如何编写代码构建神经网络的实战手册。我希望这本书能够帮助更多想要入门深度学习的爱好者，能够帮助读者扫清学习过程中的障碍，再上新台阶。

本书面向的读者包括：深度学习初学者； 对深度学习感兴趣的在校大学生； 有意向转行AI领域的IT从业人员。当然，这本书也是不错的深度学习工具手册，里面不仅有理论知识，也有示例代码。

值得一提的是，如果你已经有很高的深度学习水平了，那么可能本书不太适合你，你应该更关注深度学习的前沿理论和论文。

## 关于作者

红色石头，北京大学硕士。专注AI领域多年，爱好写作，累计写过的AI领域的原创文章超过150篇，累计读者达20W，文章阅读量超100W。写作风格是擅长以通俗化的语言来解释机器学习、深度学习的算法理论和技术细节。

个人网站：[www.redstonewill.com](www.redstonewill.com)

创办了AI技术领域的微信公众号：AI 有道（ID：redstonewill），欢迎读者关注，方便第一时间获取机器学习、深度学习等有价值的干货分享和信息资源。

![](./微信公众号：AI有道.jpg)

## 书籍目录

**第1章	深度学习基础**	1

- 1.1 深度学习概述	1

    - 1.1.1 什么是深度学习	1

    - 1.1.2 深度学习的应用场景	3

    - 1.1.3 深度学习的发展动力	4

    - 1.1.4 深度学习的未来	5

- 1.2 Python入门	6

    - 1.2.1 Python简介	6

    - 1.2.2 Python的安装	7

    - 1.2.3 Python基础知识	8

    - 1.2.4 NumPy矩阵运算	15

    - 1.2.5 Matplitlib绘图	20

- 1.3 Anaconda与Jupyter Notebook	24

    - 1.3.1 Anaconda	25

    - 1.3.2 Jupyter Notebook	27

**第2章 PyTorch**	34

- 2.1 PyTorch简介	34

    - 2.1.1 什么是PyTorch	34

    - 2.1.2 为什么使用PyTorch	35

- 2.2 PyTorch安装	36

- 2.3 张量Tensor	39

    - 2.3.1 创建Tensor	39

    - 2.3.2 Tensor的数学运算	40

    - 2.3.3 Tensor与NumPy	41

    - 2.3.4 CUDA Tensor	42

- 2.4 自动求导 autograd	43

    - 2.4.1 返回值是标量	43

    - 2.4.2 返回值是张量	44

    - 2.4.3 禁止自动求导	45

- 2.5 神经网络包nn和优化器optim	45

    - 2.5.1 torch.nn	45

    - 2.5.2 torch.optim	46

- 2.6 PyTorch线性回归	47

    - 2.6.1 线性回归基本原理	48

    - 2.6.2 PyTorch实现	49

**第3章 TensorFlow**	53

- 3.1 TensorFlow简介	53

    - 3.1.1 什么是TensorFlow	53

    - 3.1.2 为什么使用TensorFLow	54

- 3.2 TensorFlow安装	54

- 3.3 张量Tensor	56

    - 3.3.1 创建Tensor	56

    - 3.3.2 Tensor的数学运算	57

- 3.4 数据流图	58

- 3.5 会话Session	60

- 3.6 TensorFlow线性回归	62

- 3.7 TensorBoard	66

    - 3.7.1 TensorBoard代码	66

    - 3.7.2 TensorBoard显示	67

**第4章 神经网络基础**	71

- 4.1 感知机	71

    - 4.1.1 感知机模型	71

    - 4.1.2 感知机与逻辑电路	72

- 4.2 多层感知机	77

    - 4.2.1 感知机的局限性	78

    - 4.2.2 多层感知机实现异或	79

- 4.3 逻辑回归	81

    - 4.3.1 基本原理	82

    - 4.3.2 损失函数	84

    - 4.3.3 梯度下降	87

    - 4.3.4逻辑回归的Python实现	92

**第5章 神经网络**	98

- 5.1 基本结构	98

- 5.2 前向传播	100

- 5.3 激活函数	101

- 5.4 反向传播	106

- 5.5 更新参数	108

- 5.6 初始化	108

- 5.7 神经网络的Python实现	109

    - 5.7.1 准备数据	109

    - 5.7.2 参数初始化	110

    - 5.7.3 前向传播	111

    - 5.7.4 交叉熵损失	112

    - 5.7.5 反向传播	113

    - 5.7.6 更新参数	114

    - 5.7.7 构建整个神经网络模型	115

    - 5.7.8 训练	116

    - 5.7.9 预测	116

**第6章	深层神经网络**	119

- 6.1 神经网络为什么要深	119

- 6.2 符号标记	121

- 6.3 前向传播与反向传播	122

- 6.4 多分类Softmax	125

    - 6.4.1 Softmax基本原理	126

    - 6.4.2 Softmax损失函数	127

    - 6.4.3 Softmax求导	128

- 6.5 深层神经网络的Python实现	130

    - 6.5.1 准备数据	130

    - 6.5.2 参数初始化	133

    - 6.5.3 前向传播	134

    - 6.5.4 交叉熵损失	137

    - 6.5.5 反向传播	137

    - 6.5.6 更新参数	140

    - 6.5.7 构建整个神经网络	141

    - 6.5.8 训练与预测	143

**第7章	优化神经网络**	146

- 7.1 正则化	146

    - 7.1.1 什么是过拟合	146

    - 7.1.2 L1和L2正则化	149

    - 7.1.3 Dropout正则化	153

    - 7.1.4 其它正则化技巧	157

- 7.2 梯度优化	159

    - 7.2.1 BGD、SGD、MBGD	159

    - 7.2.2 Momentum GD	163

    - 7.2.3 Nesterov Momentum	165

    - 7.2.4 AdaGrad	166

    - 7.2.5 RMSprop	167

    - 7.2.6 Adam	168

    - 7.2.7 Learning Rate Decay	169

- 7.3 网络初始化与超参数调试	170

    - 7.3.1 输入标准化	171

    - 7.3.2 权重参数初始化	173

    - 7.3.3 批归一化	176

    - 7.3.4 超参数调试	179

- 7.4 模型评估与调试	183

    - 7.4.1 模型评估	183

    - 7.4.2 训练/验证/测试集	184

    - 7.4.3 偏差与方差	187

    - 7.4.4 错误分析	187

**第8章	卷积神经网络**	192

- 8.1 为什么选择CNN	192

- 8.2 CNN基本结构	193

- 8.3 卷积层	194

    - 8.3.1 卷积	194

    - 8.3.2 边缘检测	196

    - 8.3.3 填充Padding	198

    - 8.3.4 步幅Stride	199

    - 8.3.5 CNN卷积	200

    - 8.3.6 卷积层的作用	205

- 8.4 池化层	205

- 8.5 全连接层	208

- 8.6 CNN模型	210

- 8.7 典型的CNN模型	213

    - 8.7.1 LeNet-5	213

    - 8.7.2 AlexNet	214

- 8.8 CNN的PyTorch实现	215

    - 8.8.1 准备数据	215

    - 8.8.2 定义CNN模型	219

    - 8.8.3 损失函数与梯度优化	221

    - 8.8.4 训练模型	221

    - 8.8.5 测试模型	223

- 8.9 CNN的TensorFlow实现	224

    - 8.9.1 准备数据	224

    - 8.9.2 定义CNN模型	225

    - 8.9.3 损失函数与优化算法	227

    - 8.9.4 训练并测试	228

**第9章	循环神经网络**	229

- 9.1 为什么选择RNN	229

- 9.2 RNN基本结构	230

- 9.3 模型参数	232

- 9.4 梯度消失	234

- 9.5 GRU	234

- 9.6 LSTM	236

- 9.7 多种RNN模型	237

- 9.8 RNN的PyTorch实现	241

    - 9.8.1 准备数据	242

    - 9.8.2 定义RNN模型	244

    - 9.8.3 损失函数与梯度优化	246

    - 9.8.4 训练模型	246

    - 9.8.5 测试模型	247

- 9.9 RNN的TensorFlow实现	248

    - 9.9.1 准备数据	249

    - 9.9.2 定义RNN模型	249

    - 9.9.3 损失函数与优化算法	250

    - 9.9.4 训练并测试	251

**后记**	252



## 源代码目录

- ## [01_the_foundation_of_deep_learning.ipynb](https://github.com/RedstoneWill/dl-from-scratch/blob/master/01_the_foundation_of_deep_learning.ipynb)

- ## [02_pytorch_tutorial.ipynb](https://github.com/RedstoneWill/dl-from-scratch/blob/master/02_pytorch_tutorial.ipynb)

- ## [03_tensorflow_tutorial.ipynb](https://github.com/RedstoneWill/dl-from-scratch/blob/master/03_tensorflow_tutorial.ipynb)

- ## [04_neural_network_foundation.ipynb](https://github.com/RedstoneWill/dl-from-scratch/blob/master/04_neural_network_foundation.ipynb)

- ## [05_neural_network.ipynb](https://github.com/RedstoneWill/dl-from-scratch/blob/master/05_neural_network.ipynb)

- ## [06_deep_neural_network.ipynb](https://github.com/RedstoneWill/dl-from-scratch/blob/master/06_deep_neural_network.ipynb)

- ## [08_cnn_pytorch.ipynb](https://github.com/RedstoneWill/dl-from-scratch/blob/master/08_cnn_pytorch.ipynb)

- ## [08_cnn_tensorflow.ipynb](https://github.com/RedstoneWill/dl-from-scratch/blob/master/08_cnn_tensorflow.ipynb)

- ## [09_rnn_pytorch.ipynb](https://github.com/RedstoneWill/dl-from-scratch/blob/master/09_rnn_pytorch.ipynb)

- ## [09_rnn_tensorflow.ipynb](https://github.com/RedstoneWill/dl-from-scratch/blob/master/09_rnn_tensorflow.ipynb)